{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 - Depth from Focus\n",
    "\n",
    "The goal of this homework is to explore the focus properties of images captured by a device where the focus-distance can be tuned (e.g. a DSLR camera). You will write a program that takes a sequence of images captured with different focus settings, use these images to find the depth for each pixel in the scene, and then use this depth map to estimate an all-in focus image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pics/example_scene.png)\n",
    "\n",
    "\n",
    "Figure 1: An example scene to capture depth from focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pics/focus_left.png)![](pics/focus_right.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2: Two images from a focal stack sequence of the scene from Figure 1. In the left image the foremost object is in focus (the cat). In the right image, the focus is in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage import color\n",
    "import skimage \n",
    "import operator\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.cm as cm\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.patches as patches\n",
    "import skimage.morphology\n",
    "from scipy import ndimage, misc\n",
    "from skimage import data, transform, exposure\n",
    "from skimage.util import compare_images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Information on autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the code that you have to implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to complete this assignment\n",
    "<span style=\"color:white\">*To complete the assignment, you will solve 5 problems, each of which consists of a coding task and a writing task that is documented in this notebook. To achieve a passing grade, you must succesfully complete all of the coding tasks AND you must write up your results in a well-documented report.* </span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Coding Tasks: </span>\n",
    "You will implement functions in the following python files:\n",
    "- src/code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.code as code # these are the functions you have to implement\n",
    "import src.util as util # these are functions we will provide for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Writing Tasks: </span>\n",
    "\n",
    "All writing tasks necessary for a complete report are summarized at the end of this notebook.\n",
    "\n",
    "Additional questions (marked with \"*Questions*\") are posed between the different coding tasks. These questions are mainly a help for you. You should try to answer them for yourself to familiarize yourself with a specific problem. In many cases, these questions also push you in the right direction.\n",
    "\n",
    "**Important: Questions that are not posed (again) at the end of the notebook do not have to be answered in the report!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 1: Load dataset and explore </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data//scene1//' # There are 2 more scenes available in the data folder\n",
    "\n",
    "# Data downloaded from https://www.eecs.yorku.ca/~abuolaim/eccv_2018_autofocus/dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (implemened for you)\n",
    "\n",
    "imgs,diopters = util.load_focal_stack_data(path,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_imgs,dim_x,dimY,_ = imgs.shape\n",
    "\n",
    "print(imgs.shape)\n",
    "print(diopters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Check - Load Data : Did you read the files in correct order?</span>\n",
    "Reading filenames can be tricky since different OS might order them differently. It's important that the focal stack is read in the correct order. One way to check this is by plotting the read diopters and see if they give a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the plot shows line! If not, you messed up the loading part in the images. Order is important in this assignment!\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(diopters,'.')\n",
    "plt.xlabel(\"Image Index\")\n",
    "plt.ylabel(\"Diopter\")\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "# 1/diopters will give you the direct focus disance\n",
    "\n",
    "focus_distances = 1/diopters\n",
    "focus_distances = np.round(focus_distances, 3)\n",
    "plt.plot(np.arange(0,len(focus_distances)),focus_distances,'.')\n",
    "\n",
    "plt.title(\"Focus Distance - m\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "util.save_fig_as_png('plot_focus_distance_and_diopter.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Check - Investigate the scene</span>\n",
    "\n",
    "After plotting an example image (see below), look at the scene and ask yourself the questions:\n",
    " - Which parts are in focus?\n",
    " - What part of the image contains high frequency image features? \n",
    " - Try to anticpiate where the All-in-Focus might be problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot an example of the scene\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(imgs[0,:,:,:])\n",
    "plt.title(\"Example Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs.shape)\n",
    "print(diopters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Cut away data too close and too far</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're cutting a few images at the very end (focusing close to the camera) and very first (focusing really far away)\n",
    "\n",
    "imgs = imgs[3:45,:,:,:]\n",
    "diopters = diopters[3:45]\n",
    "\n",
    "\n",
    "focus_distances = 1/diopters\n",
    "print(focus_distances.shape)\n",
    "focus_distances = np.round(focus_distances, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Explore the focal stack</span>\n",
    "\n",
    "You'll now have to implement the code.get_patch_ranges() function. You will have to set some reasonable regions. Look at the comments in the function for further instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_patches = code.get_patch_ranges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigat my_patches a bit\n",
    "print(my_patches[2,:])\n",
    "print(my_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.display_patches(imgs[0,:,:,:],my_patches)\n",
    "\n",
    "util.save_fig_as_png('display_chosen_patches.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now display the different regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at the focal stack of the complete image in a large gridded view. The function util.plot_images_grid()  shows the focal stack in an image grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to adapt the size so that it fits well\n",
    "plt.figure(figsize=(15,9))\n",
    "# This takes the default parameters. Hence it should display the complete images as well as a 3x3 grid of images\n",
    "util.plot_images_grid(imgs,focus_distances)\n",
    "\n",
    "util.save_fig_as_png(\"focal_stack_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now visualize it for cropped regions of your patches so that you can exlore the focal stack a bit more in detail\n",
    "\n",
    "Note: Make sure that your plot_images_grid can handle all parameters. I.e. you should be able to run the cell from above and the cell below without making any changes to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plots = 5\n",
    "n_plots = 4\n",
    "\n",
    "for k in range(my_patches.shape[1]):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    xmin = my_patches[k,0]\n",
    "    ymin = my_patches[k,2]\n",
    "    xmax = my_patches[k,1]\n",
    "    ymax = my_patches[k,3]\n",
    "    util.plot_images_grid(imgs,focus_distances,m_plots,n_plots,xmin,xmax,ymin,ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 2: Correct for magnification</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there is a small change in magnification that occurs as you change the focus. Once you have captured a focal stack of N images, you will need to compensate for this small change in magnification.\n",
    "\n",
    "*Questions:* How can you see this in the images? What is an indicator for this?\n",
    "\n",
    "The following snippet might help you realize this better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize why you have to rescale\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.imshow(imgs[0,:,:,:])\n",
    "plt.title(\"Focused at \" + str(focus_distances[0]) + ' m',fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.imshow(imgs[-1,:,:,:])\n",
    "plt.title(\"Focused at \" + str(focus_distances[-1]) + ' m',fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "util.save_fig_as_png(\"two_images_at_different_focus_distances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let the focal stack be represented by $I(x,y,k)$, where $k \\in [0,N-1]$ is the index into the focal stack and $(x,y)$ are pixel coordinates. Let $v_k$ be the set of focal distances (in meters) used in your experiments in part 1. You can calculate the lens-to-sensor distance during each exposure $u_k$ using the Gaussian Lens Law. The camera used has a focal length of $5.2 mm$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> $ \\frac{1}{u_k} = \\frac{1}{f} - \\frac{1}{v_k}$ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive the formula for u_k in the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> $ u_k = \\text{You have to derive this}$ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With u_k you can calculate the magnification factor for every focal distance by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> $ m_k = \\frac{u_N}{u_k}$ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a millimeter\n",
    "mm = 1/1000.0\n",
    "# Focal Length of 5.2 mm\n",
    "focal_length = 5.2*mm \n",
    "\n",
    "magnifications = code.calculate_magnification_factor(diopters,focal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that the plot below looks similair to the image provided in the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(focus_distances,magnifications)\n",
    "plt.xlabel(\"Focus distance [m]\")\n",
    "plt.ylabel(\"Magnification factor\")\n",
    "\n",
    "util.save_fig_as_png(\"focus_distance_vs_magnification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Implement a crop function</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will implement a function that crops an image from the center of an image.\n",
    "This function becomes very handy in the magnification-correction function. First we have to rescale the image, then we have to crop it back to the original resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  skimage.data.astronaut()\n",
    "\n",
    "plt.imshow(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code.crop_image will crop an image at center that has the dimension defined by bounding\n",
    "bounding = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cropped = code.crop_image(test, bounding)\n",
    "\n",
    "# This image should be cropped exactly at the center of the image\n",
    "print(test_cropped.shape)\n",
    "plt.imshow(test_cropped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Implement scale image and crop in center</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipped with the crop_center image method you can now implement the code.scale_image_and_crop method that will allow you to compensate for the slight change in magnification.\n",
    "# You have to think about how to implement this! We leave this up to you figure out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs[0,:,:,:].shape)\n",
    "out = code.scale_image_and_crop(imgs[0,:,:,:],magnifications[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test if the magnification correction has worked\n",
    "\n",
    "plt.figure(figsize=(20,22))\n",
    "\n",
    "plt.subplot(131)\n",
    "\n",
    "plt.imshow(imgs[0,:,:,:])\n",
    "plt.title(\"Focused at \" + str(focus_distances[0]) + 'm - Before correction',fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.title(\"Focused at \" + str(focus_distances[0]) + 'm - After correction',fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "\n",
    "plt.imshow(imgs[-1,:,:,:])\n",
    "plt.title(\"Focused at \" + str(focus_distances[-1]) + 'm',fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "util.save_fig_as_png(\"after_magnification_correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question for the report:* How do you check if the magnification correction has worked? At which parts in the image can this be seen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Implement a function that scales all images and crops them in the center</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know how to correct one image, we have to implement a function that corrects for all images:\n",
    "imgs_corrected = code.correct_focal_stack_scaling(imgs,diopters,focal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgs.shape) # Should be same size\n",
    "print(imgs_corrected.shape) # should be same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Visualize the quality of the rescaling operations</span>\n",
    "\n",
    "Use the following website to get inspiration from:\n",
    "https://scikit-image.org/docs/dev/auto_examples/applications/plot_image_comparison.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imgs_corrected[0,:,:,:]\n",
    "img2 = imgs_corrected[-1,:,:,:] # If you're not familair with -1 in numpy arrays google it!!!\n",
    "\n",
    "util.plot_comparison(img1, img2, method='checkerboard')\n",
    "util.save_fig_as_png(\"checkerboard_comparison\")\n",
    "\n",
    "util.plot_comparison(img1, img2, method='diff')\n",
    "util.save_fig_as_png(\"diff_comparison\")\n",
    "\n",
    "util.plot_comparison(img1, img2, method='blend')\n",
    "util.save_fig_as_png(\"blend_comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Visualize the quality of the rescaling operations with methods from before</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plots = 5\n",
    "n_plots = 4\n",
    "\n",
    "for k in range(my_patches.shape[1]):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    xmin = my_patches[k,0]\n",
    "    ymin = my_patches[k,2]\n",
    "    xmax = my_patches[k,1]\n",
    "    ymax = my_patches[k,3]\n",
    "    util.plot_images_grid(imgs_corrected,focus_distances,m_plots,n_plots,xmin,xmax,ymin,ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 3: Focus Measure to calculate Depth-map</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have corrected your focal stack, you will now write a program to compute a depth map of the scene. We will use the squared laplacian as a focus measure. Our focus measure is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> $ M(x,y,k) = \\sum\\limits_{i = x - k }^{x + K} \\sum\\limits_{i = x - k }^{x + K} |  \\nabla^2 I'(i,j,k)|^2 $ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where K is a variable that is chosen based on the amount of texture in the scene. In other words, this operation performs a convolution with a PSF that is a square. \n",
    "\n",
    "In principle we could also define other structural elements to do the convolution, e.g. a disk which has the property to be radial symmetric. Different structural elements are e.g. shown here: https://scikit-image.org/docs/dev/auto_examples/numpy_operations/plot_structuring_elements.html#sphx-glr-auto-examples-numpy-operations-plot-structuring-elements-py\n",
    "\n",
    "\n",
    "\n",
    "The depth can then be calculated for each pixel by finding the index into the focal stack  where the focus is maximum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> $ D(x,y) = \\text{arg max  } M(x,y,k) $ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing this equation will tell you which image in the stack a given pixel is in focus. You will have to refer to your experiment in the former part to determine what the actual focal distance was for that image which you can read from the diopters. Use above equations to compute the depth of the scence from the focal your processed earlier. Here are a few guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can implement the Laplacian operator in Eq. 4 as a linear filter using the following kernel:\n",
    "<br>\n",
    "<h1><center>$L_{ij} = \\frac{1}{6} \\begin{bmatrix}\n",
    "1 & 4 & 1\\\\ \n",
    "4 & -20 & 4 \\\\ \n",
    "1 & 4 & 1\n",
    "\\end{bmatrix} $ <\\center><\\h1>\n",
    "<br>\n",
    "    \n",
    "You can then implement the laplacian operator as a convolution with the captured image:\n",
    "    \n",
    "<h1><center>$\n",
    "\\nabla^2 I(x,y,k) = \\sum\\limits_{i = -1}^{1} \\sum\\limits_{j = -1}^{1} L(i,j)\\cdot I(x-i,y-j,k)\n",
    "$<\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Do not write your own convolution code, you can simply use any convolution routine available in many Python packages to do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = code.get_laplacian()\n",
    "\n",
    "plt.imshow(L)\n",
    "plt.colorbar()\n",
    "plt.title('Laplacian Kernel')\n",
    "\n",
    "util.save_fig_as_png(\"laplacian_kernel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs_corrected[0,:,:,:]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_disk = skimage.morphology.disk(25)\n",
    "K_square = skimage.morphology.square(25)\n",
    "\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.subplot(121)\n",
    "util.plot_with_colorbar(K_disk)\n",
    "plt.subplot(122)\n",
    "util.plot_with_colorbar(K_square)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Calculate the laplacian-image</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_laplacian = code.filter_laplacian(rgb2gray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(np.log(img_laplacian+1))\n",
    "# We normalize the image between 0 and 1 and we're also using the logarithm for an enhancement of the edges\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "util.save_fig_as_png(\"after_laplacian_filter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Filter the image with average-mask</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 50\n",
    "out_filtered_square = code.filter_element(img_laplacian,diameter,element='square')\n",
    "out_filtered_disk = code.filter_element(img_laplacian,diameter,element='disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(out_filtered_square)\n",
    "\n",
    "util.save_fig_as_png(\"after_average_mask_square\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(out_filtered_disk)\n",
    "\n",
    "util.save_fig_as_png(\"after_average_mask_disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Apply a maximum-filter for the range</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's stick with the square structure element from before\n",
    "\n",
    "out_maximum = code.filter_maximum(out_filtered_square,250)\n",
    "\n",
    "plt.imshow(out_maximum)\n",
    "\n",
    "util.save_fig_as_png(\"maximum_filter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Implement a function that performs the complete filtering</span>\n",
    "\n",
    "Implement a function which combines the laplacian filter and the structural element filtering. Further implement the norm_image() function in code.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_element = 300\n",
    "diameter_max = 50\n",
    "\n",
    "img_idx = 30\n",
    "output = code.filter_images(imgs_corrected[img_idx,:,:,:],diameter_element,diameter_max,element='disk')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(code.norm_image(output))\n",
    "\n",
    "util.save_fig_as_png(\"complete_filtering\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Filter the complete focal stack</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_corrected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the values that you found best from above\n",
    "\n",
    "#diameter_element = 50\n",
    "#diameter_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.zeros(imgs_corrected.shape[0:3]) # Because we get rid of the colors since we only work on the grayscales images now\n",
    "\n",
    "for k in range(imgs_corrected.shape[0]):\n",
    "    print(\"Process Image \" + str(k))\n",
    "    res[k,:,:] = code.filter_images(imgs_corrected[k,:,:,:],diameter_element,diameter_max,element='square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Visualize the filter maps</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "print(focus_distances.shape)\n",
    "util.plot_filter_maps(res,focus_distances)\n",
    "plt.tight_layout()\n",
    "\n",
    "util.save_fig_as_png(\"filter_maps_all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 4: Extract the most focused points to create an All-In-Focus Image</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recap what we have achieved by now:\n",
    "1. We have corrected the focal stack for magnfication\n",
    "2. We have applied a laplacian filter and an average filter to the focal stack  \n",
    "  *Question:* Why?\n",
    "\n",
    "The latest result will be our focus metric, but we haven't analyzed yet how well this has actually worked. That is what we are going to investigate with the next methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will pick a few coordinates on the image where we extract the focus-metric along the focal-stack.\n",
    "\n",
    "Before you go and implement this, please think what do you expect? Make sure that you've understood what you will have to plot and what you expect, otherwise you might have troubles debugging your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that picks several points on the image that are interesting to investigate more:\n",
    "x,y = util.get_points_for_focus(imgs.shape[1],imgs.shape[2],3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will use a function that displays the points as an overlay over the image so that you can make sure that you actually have points that are interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "util.plot_chosen_points(img,x,y)\n",
    "\n",
    "util.save_fig_as_png(\"plot_chosen_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to investigate how well the focus measure performs over the complete focal stack by plotting the focus-measure curves for the points that you've just chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "util.plot_focus_metric_distances(res,focus_distances, x,y)\n",
    "plt.title(\"Focus Metric without normalization\")\n",
    "\n",
    "util.save_fig_as_png(\"plot_focus_metric\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Analyze the line plots of the depth maps. Looking at the scene, do they make sense to you ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 5: Recover an all-focus image of the scene</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pics/depth_map.png)\n",
    "\n",
    "Figure 3: A depth index map computed from the focal stack of Fig. 2. The depth map was calculated using equations used above with a value of K=5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have computed a depth map of the scene, you can use it to recover an all-focus image of the scene. The all-focus image $A(x,y)$ can be computed simply as\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center> $ A(x,y) = I_{corr}(x,y,D(x,y))$ <\\center><\\h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pics/all_in_focus.png)\n",
    "\n",
    "Figure 4: An all-focus image computed from the focal stack of Figure 2 and the depth map of Figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Recover the depth map</span>\n",
    "Use the method described above and look at the function for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map,depth_map_idx = code.compute_depth_map(res,focus_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Those images will probably not look exactly like the images we've provided in the examples! \n",
    "# Don't try to get exactly the same images. There are so many different parameters in play\n",
    "# and trying to get exactly the same is just useless time spent on your side\n",
    "# You should get images that look conceptually the same i.e. have similair information in depth!\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "util.plot_with_colorbar(depth_map,vmax=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "util.save_fig_as_png(\"computed_depth_map\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "util.plot_with_colorbar(depth_map_idx)\n",
    "plt.tight_layout()\n",
    "\n",
    "util.save_fig_as_png(\"computed_depth_map_indices\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">Task: Calculate the All-in-Focus Image</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_focus = code.combine_to_compute_all_in_focus(imgs_corrected,depth_map_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(all_in_focus)\n",
    "\n",
    "util.save_fig_as_png(\"all_in_focus_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:orange\">Problem 6: Try a different dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "path = 'Data//scene6//' # There are 2 more scenes available in the data folder\n",
    "imgs,diopters = util.load_focal_stack_data(path)\n",
    "focus_distances = 1/diopters\n",
    "print(\"Images loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_corrected = code.correct_focal_stack_scaling(imgs,diopters,focal_length)\n",
    "\n",
    "res = np.zeros(imgs_corrected.shape[0:3]) # Because we get rid of the colors since we only work on the grayscales images now\n",
    "for k in range(imgs_corrected.shape[0]):\n",
    "    print(\"Process Image \" + str(k))\n",
    "    res[k,:,:] = code.filter_images(imgs_corrected[k,:,:,:],diameter_element,diameter_max,element='square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map,depth_map_idx = code.compute_depth_map(res,focus_distances)\n",
    "all_in_focus = code.combine_to_compute_all_in_focus(imgs_corrected,depth_map_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(all_in_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <span style=\"color:blue\">Writing Tasks: </span>\n",
    "\n",
    "Please refer to the latex template for your writeups. Your latex report should document:\n",
    "\n",
    "### <span style=\"color:blue\">1. Abstract: </span>\n",
    "3-4 sentences motivating the Depth-of-Field problem and the solution approach that this assignment introduces.\n",
    "\n",
    "### <span style=\"color:blue\">2. Introduction: </span>\n",
    "This section should answer: What is depth of field (DoF)? Why is a limited DoF problematic for some imaging applications? How can the DoF be extended by non-computational means? Explain the tradeoff between DoF and lateral resolution of an image taken with an optical system. Why is a limited DoF desired in portrait photography?\n",
    "\n",
    "### <span style=\"color:blue\">3. Methods: </span>\n",
    "In this section you describe the solution approaches that you pursued to solve Problems 1-6.\n",
    "Your descriptions should include the answers to the following questions:\n",
    "\n",
    "**Problem 1:** Why does it make sense to visualize the focal stack in a an image grid? Can you think of other useful visualisation methods?\n",
    "\n",
    "**Problem 2:** Why do you observe the mentioned change in maginification (explain with a formula)? At which parts of the images in the focal stack is this change obvious? Why do you need to correct for that and what happens if you don't? What have you done to correct for the change in magnification in the focal step? Describe the method in your own words. Did it work?\n",
    "We introduced 3 different methods to visually check the maginification correction. What is in your opinion the best method? Explain why (Hint: look at spatial features)!\n",
    "\n",
    "**Problem 3:** What happens if you convolve an image with a Laplacian kernel? How can this property be used to determine wether an image region is in focus or not? Can you think of a scenario where this approach fails?\n",
    "\n",
    "**Problem 4:** What do you see in the focus metric? Do the results of your calculated focus metric make sense to you? Describe if your result is correct by using the example of two concrete points in the scene. Why did you pick exactly these two points? Is there also a point where the focus metric does not tell you much (failure case)?\n",
    "\n",
    "**Problem 5:** What is a depth map and how does it help you to calculate an all in focus image? What did you do to calculate the all in focus image? Why did you decide for this approach?\n",
    "\n",
    "**Problem 6:** Why did you pick the dataset that you have picked and not the other one? Did everything work as expected from the first attempt on? If not, why?\n",
    "\n",
    "\n",
    "### <span style=\"color:blue\">4. Results: </span>\n",
    "Not every image needs to be shown. Only show your best results or the results that give you most insight in a specific topic that you want to discuss. Choose well which images you want to include to form a coherent story. \n",
    "\n",
    "### <span style=\"color:blue\">5. Conclusion: </span> \n",
    "A very short summary of what you've learned and what you think about the assignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
